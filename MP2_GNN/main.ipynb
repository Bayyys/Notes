{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb6c7cde",
   "metadata": {},
   "source": [
    "# 基于GNN的金融异常检测任务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44e7b26",
   "metadata": {},
   "source": [
    "## 1. 实验介绍\n",
    "\n",
    "反欺诈是金融行业永恒的主题，在互联网金融信贷业务中，数字金融反欺诈技术已经得到广泛应用并取得良好效果，这其中包括了近几年迅速发展并在各个领域\n",
    "得到越来越广泛应用的图神经网络。本项目以互联网智能风控为背景，从用户相互关联和影响的视角，探索满足风控反欺诈领域需求的，可拓展、高效的图神经\n",
    "网络应用方案，从而帮助更好地识别欺诈用户。\n",
    "\n",
    "本项目主要关于实现预测模型(**不限于图神经网络**)，进行节点异常检测任务，并验证模型精度。而本项目基于的数据集[DGraph](https://dgraph.xinye.com/introduction)，[DGraph](https://dgraph.xinye.com/introduction)\n",
    "是大规模动态图数据集的集合，由真实金融场景中随着时间演变事件和标签构成。\n",
    "\n",
    "### 1.1 实验目的\n",
    "\n",
    "- 了解如何使用Pytorch进行神经网络训练\n",
    "- 了解如何使用Pytorch-geometric等图网络深度学习库进行简单图神经网络设计(推荐使用GAT, GraphSAGE模型)。\n",
    "- 了解如何利用MO平台进行模型性能评估。\n",
    "\n",
    "### 1.2 预备知识\n",
    "- 具备一定的深度学习理论知识，如卷积神经网络、损失函数、优化器，训练策略等。\n",
    "- 了解并熟悉Pytorch计算框架。\n",
    "- 学习Pytorch-geometric，请前往：https://pytorch-geometric.readthedocs.io/en/latest/\n",
    "    \n",
    "### 1.3实验环境\n",
    "- numpy = 1.18.5  \n",
    "- pytorch = 1.4.0  \n",
    "- torch_geometric = 1.7.0  \n",
    "- torch_scatter = 2.0.3  \n",
    "- torch_sparse = 0.5.1  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc739378",
   "metadata": {},
   "source": [
    "## 2. 实验内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc97c99c",
   "metadata": {},
   "source": [
    "### 2.1 数据集信息\n",
    "DGraph-Fin 是一个由数百万个节点和边组成的有向无边权的动态图。它代表了Finvolution Group用户之间的社交网络，其中一个节点对应一个Finvolution 用户，从一个用户到另一个用户的边表示**该用户将另一个用户视为紧急联系人**。\n",
    "下面是`位于dataset/DGraphFin目录`的DGraphFin数据集的描述:\n",
    "```\n",
    "x:  20维节点特征向量\n",
    "y:  节点对应标签，一共包含四类。其中类1代表欺诈用户而类0代表正常用户(实验中需要进行预测的两类标签)，类2和类3则是背景用户，即无需预测其标签。\n",
    "edge_index:  图数据边集,每条边的形式(id_a,id_b)，其中ids是x中的索引\n",
    "edge_type: 共11种类型的边\n",
    "edge_timestamp: 脱敏后的时间戳\n",
    "train_mask, valid_mask, test_mask: 训练集，验证集和测试集掩码\n",
    "```\n",
    "本预测任务为识别欺诈用户的节点预测任务,只需要将欺诈用户（Class 1）从正常用户（Class 0）中区分出来。需要注意的是，其中测试集中样本对应的label**均被标记为-100**。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba15aa2",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 2.2 导入相关包\n",
    "\n",
    "导入相应模块，设置数据集路径、设备等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)    #查看cpu版本\n",
    "print(torch.version.cuda)     #查看gpu版本"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from utils import DGraphFin\n",
    "from utils.utils import prepare_folder\n",
    "from utils.evaluator import Evaluator\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "\n",
    "#设置gpu设备\n",
    "device = 0\n",
    "device = f'cuda:{device}' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "4a7156e5",
   "metadata": {},
   "source": [
    "### 2.3 数据处理\n",
    "\n",
    "在使用数据集训练网络前，首先需要对数据进行归一化等预处理，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a398f513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "read_dgraph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "path='./datasets/632d74d4e2843a53167ee9a1-momodel/' #数据保存路径\n",
    "save_dir='./results/' #模型保存路径\n",
    "dataset_name='DGraph'\n",
    "dataset = DGraphFin(root=path, name=dataset_name, transform=T.ToSparseTensor())\n",
    "\n",
    "nlabels = dataset.num_classes\n",
    "if dataset_name in ['DGraph']:\n",
    "    nlabels = 2    #本实验中仅需预测类0和类1\n",
    "\n",
    "data = dataset[0]\n",
    "data.adj_t = data.adj_t.to_symmetric() #将有向图转化为无向图\n",
    "\n",
    "\n",
    "if dataset_name in ['DGraph']:\n",
    "    x = data.x\n",
    "    x = (x - x.mean(0)) / x.std(0)\n",
    "    data.x = x\n",
    "if data.y.dim() == 2:\n",
    "    data.y = data.y.squeeze(1)\n",
    "\n",
    "split_idx = {'train': data.train_mask, 'valid': data.valid_mask, 'test': data.test_mask}  #划分训练集，验证集\n",
    "\n",
    "train_idx = split_idx['train']\n",
    "result_dir = prepare_folder(dataset_name,'mlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c09d1",
   "metadata": {},
   "source": [
    "这里我们可以查看数据各部分维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed683776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3700550, 20], edge_attr=[4300999], y=[3700550], train_mask=[857899], valid_mask=[183862], test_mask=[183840], adj_t=[3700550, 3700550, nnz=7994520])\n",
      "torch.Size([3700550, 20])\n",
      "torch.Size([3700550, 20])\n",
      "torch.Size([3700550])\n",
      "tensor([   2,    2, -100,  ...,    2,    0,    0])\n",
      "tensor([2763073,  548373,  699951,  ...,  220416, 2843218, 2544039])\n",
      "tensor([2683077, 2842796,  424346,  ..., 1345318,  458653, 2675150])\n",
      "tensor([2825811, 1815662, 1229948,  ...,  417443, 2532587, 1678153])\n",
      "tensor([2763073,  548373,  699951,  ...,  220416, 2843218, 2544039])\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(data.x.shape)  #feature\n",
    "print(data.x.shape)  #feature\n",
    "print(data.y.shape)  #label\n",
    "print(data.y)\n",
    "print(data.train_mask)\n",
    "print(data.test_mask)\n",
    "print(data.valid_mask)\n",
    "print(train_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dc31c7",
   "metadata": {},
   "source": [
    "### 2.4 定义模型\n",
    "这里我们使用简单的多层感知机作为例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc8b8b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self\n",
    "                 , in_channels\n",
    "                 , hidden_channels\n",
    "                 , out_channels\n",
    "                 , num_layers\n",
    "                 , dropout\n",
    "                 , batchnorm=True):\n",
    "        super(MLP, self).__init__()\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        self.batchnorm = batchnorm\n",
    "        if self.batchnorm:\n",
    "            self.bns = torch.nn.ModuleList()\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "            if self.batchnorm:\n",
    "                self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        if self.batchnorm:\n",
    "            for bn in self.bns:\n",
    "                bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x):    \n",
    "        for i, lin in enumerate(self.lins[:-1]):\n",
    "            x = lin(x)\n",
    "            if self.batchnorm:\n",
    "                x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d60061",
   "metadata": {},
   "source": [
    "配置后续训练、验证、推理用到的参数。可以调整以下超参以提高模型训练后的验证精度：\n",
    "\n",
    "- `epochs`：在训练集上训练的代数；\n",
    "- `lr`：学习率；\n",
    "- `num_layers`：网络的层数；\n",
    "- `hidden_channels`：隐藏层维数；\n",
    "- `dropout`：dropout比例；\n",
    "- `weight_decay`：正则化项的系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be91d940",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_parameters = {\n",
    "    'lr': 0.01\n",
    "    , 'num_layers': 2\n",
    "    , 'hidden_channels': 128\n",
    "    , 'dropout': 0.0\n",
    "    , 'batchnorm': False\n",
    "    , 'weight_decay': 5e-7\n",
    "                  }\n",
    "epochs = 200\n",
    "log_steps =10 # log记录周期"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b4810",
   "metadata": {},
   "source": [
    "初始化模型，并使用**Area Under the Curve (AUC)** 作为模型评价指标来衡量模型的表现。AUC通过对ROC曲线下各部分的面积求和而得。\n",
    "\n",
    "具体计算过程参见 https://github.com/scikit-learn/scikit-learn/blob/baf828ca1/sklearn/metrics/_ranking.py#L363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2942b006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MLP initialized\n"
     ]
    }
   ],
   "source": [
    "para_dict = mlp_parameters\n",
    "model_para = mlp_parameters.copy()\n",
    "model_para.pop('lr')\n",
    "model_para.pop('weight_decay')\n",
    "model = MLP(in_channels=data.x.size(-1), out_channels=nlabels, **model_para).to(device)\n",
    "print(f'Model MLP initialized')\n",
    "\n",
    "\n",
    "eval_metric = 'auc'  #使用AUC衡量指标\n",
    "evaluator = Evaluator(eval_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8747cc",
   "metadata": {},
   "source": [
    "### 2.5 训练\n",
    "\n",
    "使用训练集中的节点用于训练模型，并使用验证集进行挑选模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c11f0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, train_idx, optimizer):\n",
    "     # data.y is labels of shape (N, ) \n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    out = model(data.x[train_idx])\n",
    "\n",
    "    loss = F.nll_loss(out, data.y[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1122250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data, split_idx, evaluator):\n",
    "    # data.y is labels of shape (N, )\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        losses, eval_results = dict(), dict()\n",
    "        for key in ['train', 'valid']:\n",
    "            node_id = split_idx[key]\n",
    "            \n",
    "            out = model(data.x[node_id])\n",
    "            y_pred = out.exp()  # (N,num_classes)\n",
    "            \n",
    "            losses[key] = F.nll_loss(out, data.y[node_id]).item()\n",
    "            eval_results[key] = evaluator.eval(data.y[node_id], y_pred)[eval_metric]\n",
    "\n",
    "    return eval_results, losses, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c26fa1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2946\n",
      "Epoch: 10, Loss: 0.0880, Train: 64.275, Valid: 64.651 \n",
      "Epoch: 20, Loss: 0.0953, Train: 68.205, Valid: 67.830 \n",
      "Epoch: 30, Loss: 0.0809, Train: 69.551, Valid: 68.857 \n",
      "Epoch: 40, Loss: 0.0681, Train: 69.887, Valid: 69.603 \n",
      "Epoch: 50, Loss: 0.0650, Train: 69.387, Valid: 69.230 \n",
      "Epoch: 60, Loss: 0.0651, Train: 69.699, Valid: 69.473 \n",
      "Epoch: 70, Loss: 0.0645, Train: 70.595, Valid: 70.271 \n",
      "Epoch: 80, Loss: 0.0644, Train: 70.857, Valid: 70.468 \n",
      "Epoch: 90, Loss: 0.0643, Train: 70.902, Valid: 70.514 \n",
      "Epoch: 100, Loss: 0.0642, Train: 71.109, Valid: 70.673 \n",
      "Epoch: 110, Loss: 0.0641, Train: 71.261, Valid: 70.793 \n",
      "Epoch: 120, Loss: 0.0641, Train: 71.385, Valid: 70.864 \n",
      "Epoch: 130, Loss: 0.0640, Train: 71.479, Valid: 70.931 \n",
      "Epoch: 140, Loss: 0.0640, Train: 71.575, Valid: 70.991 \n",
      "Epoch: 150, Loss: 0.0639, Train: 71.656, Valid: 71.043 \n",
      "Epoch: 160, Loss: 0.0639, Train: 71.730, Valid: 71.091 \n",
      "Epoch: 170, Loss: 0.0639, Train: 71.799, Valid: 71.132 \n",
      "Epoch: 180, Loss: 0.0639, Train: 71.860, Valid: 71.167 \n",
      "Epoch: 190, Loss: 0.0638, Train: 71.918, Valid: 71.198 \n",
      "Epoch: 200, Loss: 0.0638, Train: 71.971, Valid: 71.227 \n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters()))  #模型总参数量\n",
    "\n",
    "model.reset_parameters()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=para_dict['lr'], weight_decay=para_dict['weight_decay'])\n",
    "best_valid = 0\n",
    "min_valid_loss = 1e8\n",
    "\n",
    "for epoch in range(1,epochs + 1):\n",
    "    loss = train(model, data, train_idx, optimizer)\n",
    "    eval_results, losses, out = test(model, data, split_idx, evaluator)\n",
    "    train_eval, valid_eval = eval_results['train'], eval_results['valid']\n",
    "    train_loss, valid_loss = losses['train'], losses['valid']\n",
    "\n",
    "    if valid_loss < min_valid_loss:\n",
    "        min_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), save_dir+'/model.pt') #将表现最好的模型保存\n",
    "\n",
    "    if epoch % log_steps == 0:\n",
    "        print(f'Epoch: {epoch:02d}, '\n",
    "              f'Loss: {loss:.4f}, '\n",
    "              f'Train: {100 * train_eval:.3f}, ' # 我们将AUC值乘上100，使其在0-100的区间内\n",
    "              f'Valid: {100 * valid_eval:.3f} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a103a55",
   "metadata": {
    "inputHidden": false
   },
   "source": [
    "### 2.6 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38754018",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(save_dir+'/model.pt')) #载入验证集上表现最好的模型\n",
    "def predict(data,node_id):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    :param node_id: int, 需要进行预测节点的下标\n",
    "    :return: tensor, 类0以及类1的概率, torch.size[1,2]\n",
    "    \"\"\"\n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        out = model(data.x[node_id])\n",
    "        y_pred = out.exp()  # (N,num_classes)\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a5b2fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9969, 0.0031])\n",
      "节点 0 预测对应的标签为:0, 为正常用户。\n",
      "tensor([0.9638, 0.0362])\n",
      "节点 200 预测对应的标签为:0, 为正常用户。\n"
     ]
    }
   ],
   "source": [
    "dic={0:\"正常用户\",1:\"欺诈用户\"}\n",
    "node_idx = 0\n",
    "y_pred = predict(data, node_idx)\n",
    "print(y_pred)\n",
    "print(f'节点 {node_idx} 预测对应的标签为:{torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')\n",
    "\n",
    "node_idx = 200\n",
    "y_pred = predict(data, node_idx)\n",
    "print(y_pred)\n",
    "print(f'节点 {node_idx} 预测对应的标签为:{torch.argmax(y_pred)}, 为{dic[torch.argmax(y_pred).item()]}。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(data.x.shape[0]):\n",
    "        results.append(predict(data, i).unsqueeze_(0))\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[1, 2, 5, 4]]), tensor([[1, 2, 3, 4]]), tensor([[2, 2, 3, 4]])]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T1 = torch.tensor([1,2,5,4]).unsqueeze_(0)\n",
    "T2 = torch.tensor([1,2,3,4]).unsqueeze_(0)\n",
    "T3 = torch.tensor([2,2,3,4]).unsqueeze_(0)\n",
    "a = []\n",
    "a.append(T1)\n",
    "a.append(T2)\n",
    "a.append(T3)\n",
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[0.9969, 0.0031]]),\n tensor([[0.9739, 0.0261]]),\n tensor([[0.9914, 0.0086]]),\n tensor([[0.9711, 0.0289]]),\n tensor([[0.9931, 0.0069]]),\n tensor([[0.9680, 0.0320]]),\n tensor([[0.9839, 0.0161]]),\n tensor([[0.9923, 0.0077]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9870, 0.0130]]),\n tensor([[0.9941, 0.0059]]),\n tensor([[9.9967e-01, 3.2816e-04]]),\n tensor([[0.9897, 0.0103]]),\n tensor([[0.9941, 0.0059]]),\n tensor([[0.9780, 0.0220]]),\n tensor([[0.9848, 0.0152]]),\n tensor([[0.9819, 0.0181]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9739, 0.0261]]),\n tensor([[0.9833, 0.0167]]),\n tensor([[0.9919, 0.0081]]),\n tensor([[0.9957, 0.0043]]),\n tensor([[0.9717, 0.0283]]),\n tensor([[0.9923, 0.0077]]),\n tensor([[0.9965, 0.0035]]),\n tensor([[0.9977, 0.0023]]),\n tensor([[0.9874, 0.0126]]),\n tensor([[0.9897, 0.0103]]),\n tensor([[0.9968, 0.0032]]),\n tensor([[0.9666, 0.0334]]),\n tensor([[0.9911, 0.0089]]),\n tensor([[0.9956, 0.0044]]),\n tensor([[0.9943, 0.0057]]),\n tensor([[0.9986, 0.0014]]),\n tensor([[0.9962, 0.0038]]),\n tensor([[0.9807, 0.0193]]),\n tensor([[0.9914, 0.0086]]),\n tensor([[0.9968, 0.0032]]),\n tensor([[0.9982, 0.0018]]),\n tensor([[0.9975, 0.0025]]),\n tensor([[9.9993e-01, 7.0462e-05]]),\n tensor([[0.9834, 0.0166]]),\n tensor([[0.9724, 0.0276]]),\n tensor([[0.9701, 0.0299]]),\n tensor([[9.9981e-01, 1.8896e-04]]),\n tensor([[0.9954, 0.0046]]),\n tensor([[0.9943, 0.0057]]),\n tensor([[0.9831, 0.0169]]),\n tensor([[0.9849, 0.0151]]),\n tensor([[1.0000e+00, 1.7549e-06]]),\n tensor([[0.9904, 0.0096]]),\n tensor([[0.9882, 0.0118]]),\n tensor([[0.9859, 0.0141]]),\n tensor([[0.9716, 0.0284]]),\n tensor([[0.9792, 0.0208]]),\n tensor([[0.9725, 0.0275]]),\n tensor([[0.9831, 0.0169]]),\n tensor([[0.9856, 0.0144]]),\n tensor([[0.9764, 0.0236]]),\n tensor([[0.9970, 0.0030]]),\n tensor([[0.9952, 0.0048]]),\n tensor([[0.9711, 0.0289]]),\n tensor([[0.9716, 0.0284]]),\n tensor([[0.9705, 0.0295]]),\n tensor([[0.9893, 0.0107]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9658, 0.0342]]),\n tensor([[0.9915, 0.0085]]),\n tensor([[0.9853, 0.0147]]),\n tensor([[0.9826, 0.0174]]),\n tensor([[0.9825, 0.0175]]),\n tensor([[0.9828, 0.0172]]),\n tensor([[0.9922, 0.0078]]),\n tensor([[0.9634, 0.0366]]),\n tensor([[0.9875, 0.0125]]),\n tensor([[0.9950, 0.0050]]),\n tensor([[0.9956, 0.0044]]),\n tensor([[0.9889, 0.0111]]),\n tensor([[0.9760, 0.0240]]),\n tensor([[0.9826, 0.0174]]),\n tensor([[0.9893, 0.0107]]),\n tensor([[0.9943, 0.0057]]),\n tensor([[0.9712, 0.0288]]),\n tensor([[0.9741, 0.0259]]),\n tensor([[0.9834, 0.0166]]),\n tensor([[0.9881, 0.0119]]),\n tensor([[0.9740, 0.0260]]),\n tensor([[0.9746, 0.0254]]),\n tensor([[0.9968, 0.0032]]),\n tensor([[0.9762, 0.0238]]),\n tensor([[0.9821, 0.0179]]),\n tensor([[0.9832, 0.0168]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9965, 0.0035]]),\n tensor([[0.9867, 0.0133]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9968, 0.0032]]),\n tensor([[0.9962, 0.0038]]),\n tensor([[0.9873, 0.0127]]),\n tensor([[0.9952, 0.0048]]),\n tensor([[0.9723, 0.0277]]),\n tensor([[0.9769, 0.0231]]),\n tensor([[0.9917, 0.0083]]),\n tensor([[0.9805, 0.0195]]),\n tensor([[0.9956, 0.0044]]),\n tensor([[0.9824, 0.0176]]),\n tensor([[0.9724, 0.0276]]),\n tensor([[9.9999e-01, 1.4940e-05]]),\n tensor([[0.9718, 0.0282]]),\n tensor([[0.9871, 0.0129]]),\n tensor([[0.9711, 0.0289]]),\n tensor([[0.9928, 0.0072]]),\n tensor([[0.9944, 0.0056]]),\n tensor([[0.9790, 0.0210]]),\n tensor([[0.9911, 0.0089]]),\n tensor([[0.9963, 0.0037]]),\n tensor([[0.9925, 0.0075]]),\n tensor([[0.9877, 0.0123]]),\n tensor([[0.9963, 0.0037]]),\n tensor([[0.9875, 0.0125]]),\n tensor([[0.9751, 0.0249]]),\n tensor([[0.9963, 0.0037]]),\n tensor([[0.9973, 0.0027]]),\n tensor([[0.9785, 0.0215]]),\n tensor([[0.9925, 0.0075]]),\n tensor([[0.9775, 0.0225]]),\n tensor([[0.9816, 0.0184]]),\n tensor([[0.9980, 0.0020]]),\n tensor([[0.9723, 0.0277]]),\n tensor([[0.9776, 0.0224]]),\n tensor([[0.9969, 0.0031]]),\n tensor([[0.9934, 0.0066]]),\n tensor([[0.9883, 0.0117]]),\n tensor([[0.9782, 0.0218]]),\n tensor([[0.9659, 0.0341]]),\n tensor([[0.9787, 0.0213]]),\n tensor([[0.9853, 0.0147]]),\n tensor([[0.9858, 0.0142]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9746, 0.0254]]),\n tensor([[0.9797, 0.0203]]),\n tensor([[0.9689, 0.0311]]),\n tensor([[0.9739, 0.0261]]),\n tensor([[0.9665, 0.0335]]),\n tensor([[0.9881, 0.0119]]),\n tensor([[0.9924, 0.0076]]),\n tensor([[0.9921, 0.0079]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9814, 0.0186]]),\n tensor([[0.9695, 0.0305]]),\n tensor([[0.9858, 0.0142]]),\n tensor([[0.9912, 0.0088]]),\n tensor([[0.9851, 0.0149]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9915, 0.0085]]),\n tensor([[0.9768, 0.0232]]),\n tensor([[0.9965, 0.0035]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9758, 0.0242]]),\n tensor([[0.9832, 0.0168]]),\n tensor([[0.9923, 0.0077]]),\n tensor([[0.9771, 0.0229]]),\n tensor([[0.9678, 0.0322]]),\n tensor([[1.0000e+00, 1.4370e-06]]),\n tensor([[0.9926, 0.0074]]),\n tensor([[0.9941, 0.0059]]),\n tensor([[0.9989, 0.0011]]),\n tensor([[0.9958, 0.0042]]),\n tensor([[0.9928, 0.0072]]),\n tensor([[0.9773, 0.0227]]),\n tensor([[0.9761, 0.0239]]),\n tensor([[0.9641, 0.0359]]),\n tensor([[0.9943, 0.0057]]),\n tensor([[0.9693, 0.0307]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9938, 0.0062]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9889, 0.0111]]),\n tensor([[0.9717, 0.0283]]),\n tensor([[0.9790, 0.0210]]),\n tensor([[0.9870, 0.0130]]),\n tensor([[0.9801, 0.0199]]),\n tensor([[0.9866, 0.0134]]),\n tensor([[0.9698, 0.0302]]),\n tensor([[0.9725, 0.0275]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9787, 0.0213]]),\n tensor([[0.9909, 0.0091]]),\n tensor([[9.9998e-01, 1.7466e-05]]),\n tensor([[0.9862, 0.0138]]),\n tensor([[0.9836, 0.0164]]),\n tensor([[0.9799, 0.0201]]),\n tensor([[0.9793, 0.0207]]),\n tensor([[0.9883, 0.0117]]),\n tensor([[0.9803, 0.0197]]),\n tensor([[0.9906, 0.0094]]),\n tensor([[0.9733, 0.0267]]),\n tensor([[0.9960, 0.0040]]),\n tensor([[0.9975, 0.0025]]),\n tensor([[0.9638, 0.0362]]),\n tensor([[0.9884, 0.0116]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[9.9996e-01, 4.0813e-05]]),\n tensor([[0.9954, 0.0046]]),\n tensor([[0.9787, 0.0213]]),\n tensor([[0.9884, 0.0116]]),\n tensor([[0.9633, 0.0367]]),\n tensor([[0.9771, 0.0229]]),\n tensor([[0.9770, 0.0230]]),\n tensor([[0.9809, 0.0191]]),\n tensor([[0.9942, 0.0058]]),\n tensor([[0.9914, 0.0086]]),\n tensor([[0.9712, 0.0288]]),\n tensor([[0.9957, 0.0043]]),\n tensor([[0.9665, 0.0335]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9698, 0.0302]]),\n tensor([[0.9894, 0.0106]]),\n tensor([[0.9923, 0.0077]]),\n tensor([[0.9913, 0.0087]]),\n tensor([[0.9694, 0.0306]]),\n tensor([[0.9687, 0.0313]]),\n tensor([[0.9804, 0.0196]]),\n tensor([[0.9765, 0.0235]]),\n tensor([[0.9969, 0.0031]]),\n tensor([[0.9917, 0.0083]]),\n tensor([[0.9758, 0.0242]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9776, 0.0224]]),\n tensor([[0.9904, 0.0096]]),\n tensor([[0.9775, 0.0225]]),\n tensor([[0.9968, 0.0032]]),\n tensor([[0.9713, 0.0287]]),\n tensor([[0.9947, 0.0053]]),\n tensor([[0.9948, 0.0052]]),\n tensor([[0.9784, 0.0216]]),\n tensor([[0.9965, 0.0035]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9761, 0.0239]]),\n tensor([[0.9855, 0.0145]]),\n tensor([[0.9875, 0.0125]]),\n tensor([[0.9844, 0.0156]]),\n tensor([[0.9737, 0.0263]]),\n tensor([[0.9989, 0.0011]]),\n tensor([[0.9747, 0.0253]]),\n tensor([[0.9815, 0.0185]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9970, 0.0030]]),\n tensor([[0.9847, 0.0153]]),\n tensor([[0.9819, 0.0181]]),\n tensor([[0.9969, 0.0031]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9818, 0.0182]]),\n tensor([[0.9762, 0.0238]]),\n tensor([[0.9722, 0.0278]]),\n tensor([[0.9972, 0.0028]]),\n tensor([[0.9955, 0.0045]]),\n tensor([[0.9858, 0.0142]]),\n tensor([[0.9980, 0.0020]]),\n tensor([[0.9907, 0.0093]]),\n tensor([[0.9825, 0.0175]]),\n tensor([[0.9756, 0.0244]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9836, 0.0164]]),\n tensor([[0.9849, 0.0151]]),\n tensor([[0.9727, 0.0273]]),\n tensor([[9.9971e-01, 2.9205e-04]]),\n tensor([[0.9804, 0.0196]]),\n tensor([[0.9944, 0.0056]]),\n tensor([[0.9689, 0.0311]]),\n tensor([[0.9780, 0.0220]]),\n tensor([[0.9977, 0.0023]]),\n tensor([[0.9779, 0.0221]]),\n tensor([[0.9819, 0.0181]]),\n tensor([[9.9915e-01, 8.5452e-04]]),\n tensor([[0.9945, 0.0055]]),\n tensor([[0.9824, 0.0176]]),\n tensor([[0.9840, 0.0160]]),\n tensor([[0.9821, 0.0179]]),\n tensor([[0.9900, 0.0100]]),\n tensor([[0.9817, 0.0183]]),\n tensor([[0.9968, 0.0032]]),\n tensor([[0.9916, 0.0084]]),\n tensor([[9.9999e-01, 7.9466e-06]]),\n tensor([[0.9867, 0.0133]]),\n tensor([[0.9987, 0.0013]]),\n tensor([[0.9906, 0.0094]]),\n tensor([[0.9973, 0.0027]]),\n tensor([[0.9848, 0.0152]]),\n tensor([[0.9758, 0.0242]]),\n tensor([[0.9736, 0.0264]]),\n tensor([[0.9754, 0.0246]]),\n tensor([[0.9950, 0.0050]]),\n tensor([[0.9968, 0.0032]]),\n tensor([[0.9775, 0.0225]]),\n tensor([[0.9854, 0.0146]]),\n tensor([[0.9969, 0.0031]]),\n tensor([[0.9860, 0.0140]]),\n tensor([[0.9745, 0.0255]]),\n tensor([[0.9908, 0.0092]]),\n tensor([[0.9932, 0.0068]]),\n tensor([[0.9932, 0.0068]]),\n tensor([[0.9862, 0.0138]]),\n tensor([[0.9917, 0.0083]]),\n tensor([[0.9875, 0.0125]]),\n tensor([[0.9952, 0.0048]]),\n tensor([[0.9755, 0.0245]]),\n tensor([[0.9820, 0.0180]]),\n tensor([[0.9913, 0.0087]]),\n tensor([[0.9979, 0.0021]]),\n tensor([[0.9817, 0.0183]]),\n tensor([[0.9765, 0.0235]]),\n tensor([[0.9921, 0.0079]]),\n tensor([[0.9875, 0.0125]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9970, 0.0030]]),\n tensor([[0.9700, 0.0300]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9921, 0.0079]]),\n tensor([[0.9962, 0.0038]]),\n tensor([[0.9682, 0.0318]]),\n tensor([[0.9642, 0.0358]]),\n tensor([[0.9909, 0.0091]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9925, 0.0075]]),\n tensor([[0.9917, 0.0083]]),\n tensor([[0.9895, 0.0105]]),\n tensor([[0.9858, 0.0142]]),\n tensor([[0.9963, 0.0037]]),\n tensor([[0.9986, 0.0014]]),\n tensor([[0.9814, 0.0186]]),\n tensor([[0.9864, 0.0136]]),\n tensor([[0.9775, 0.0225]]),\n tensor([[0.9936, 0.0064]]),\n tensor([[0.9866, 0.0134]]),\n tensor([[0.9817, 0.0183]]),\n tensor([[0.9934, 0.0066]]),\n tensor([[0.9767, 0.0233]]),\n tensor([[0.9734, 0.0266]]),\n tensor([[0.9775, 0.0225]]),\n tensor([[0.9736, 0.0264]]),\n tensor([[0.9974, 0.0026]]),\n tensor([[0.9728, 0.0272]]),\n tensor([[0.9818, 0.0182]]),\n tensor([[0.9668, 0.0332]]),\n tensor([[0.9708, 0.0292]]),\n tensor([[0.9758, 0.0242]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9792, 0.0208]]),\n tensor([[0.9683, 0.0317]]),\n tensor([[0.9889, 0.0111]]),\n tensor([[0.9928, 0.0072]]),\n tensor([[0.9952, 0.0048]]),\n tensor([[0.9859, 0.0141]]),\n tensor([[0.9872, 0.0128]]),\n tensor([[0.9717, 0.0283]]),\n tensor([[0.9757, 0.0243]]),\n tensor([[0.9767, 0.0233]]),\n tensor([[0.9762, 0.0238]]),\n tensor([[0.9811, 0.0189]]),\n tensor([[0.9755, 0.0245]]),\n tensor([[0.9836, 0.0164]]),\n tensor([[0.9747, 0.0253]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9959, 0.0041]]),\n tensor([[0.9935, 0.0065]]),\n tensor([[0.9817, 0.0183]]),\n tensor([[0.9754, 0.0246]]),\n tensor([[0.9965, 0.0035]]),\n tensor([[9.9937e-01, 6.3011e-04]]),\n tensor([[0.9882, 0.0118]]),\n tensor([[0.9984, 0.0016]]),\n tensor([[0.9909, 0.0091]]),\n tensor([[0.9791, 0.0209]]),\n tensor([[0.9907, 0.0093]]),\n tensor([[0.9825, 0.0175]]),\n tensor([[0.9954, 0.0046]]),\n tensor([[0.9949, 0.0051]]),\n tensor([[0.9683, 0.0317]]),\n tensor([[0.9945, 0.0055]]),\n tensor([[0.9671, 0.0329]]),\n tensor([[0.9729, 0.0271]]),\n tensor([[0.9761, 0.0239]]),\n tensor([[0.9736, 0.0264]]),\n tensor([[0.9803, 0.0197]]),\n tensor([[0.9908, 0.0092]]),\n tensor([[0.9963, 0.0037]]),\n tensor([[0.9837, 0.0163]]),\n tensor([[0.9952, 0.0048]]),\n tensor([[0.9963, 0.0037]]),\n tensor([[0.9876, 0.0124]]),\n tensor([[0.9965, 0.0035]]),\n tensor([[0.9890, 0.0110]]),\n tensor([[0.9932, 0.0068]]),\n tensor([[0.9958, 0.0042]]),\n tensor([[0.9666, 0.0334]]),\n tensor([[0.9811, 0.0189]]),\n tensor([[0.9962, 0.0038]]),\n tensor([[0.9888, 0.0112]]),\n tensor([[0.9977, 0.0023]]),\n tensor([[0.9732, 0.0268]]),\n tensor([[0.9988, 0.0012]]),\n tensor([[0.9886, 0.0114]]),\n tensor([[9.9997e-01, 3.0301e-05]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9956, 0.0044]]),\n tensor([[0.9835, 0.0165]]),\n tensor([[0.9885, 0.0115]]),\n tensor([[9.9957e-01, 4.3404e-04]]),\n tensor([[0.9866, 0.0134]]),\n tensor([[0.9752, 0.0248]]),\n tensor([[0.9809, 0.0191]]),\n tensor([[0.9797, 0.0203]]),\n tensor([[1.0000e+00, 3.7524e-09]]),\n tensor([[0.9952, 0.0048]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9946, 0.0054]]),\n tensor([[0.9788, 0.0212]]),\n tensor([[0.9702, 0.0298]]),\n tensor([[0.9943, 0.0057]]),\n tensor([[0.9811, 0.0189]]),\n tensor([[0.9884, 0.0116]]),\n tensor([[0.9703, 0.0297]]),\n tensor([[0.9773, 0.0227]]),\n tensor([[0.9862, 0.0138]]),\n tensor([[0.9925, 0.0075]]),\n tensor([[9.9981e-01, 1.8691e-04]]),\n tensor([[0.9892, 0.0108]]),\n tensor([[0.9802, 0.0198]]),\n tensor([[0.9711, 0.0289]]),\n tensor([[0.9948, 0.0052]]),\n tensor([[0.9789, 0.0211]]),\n tensor([[0.9800, 0.0200]]),\n tensor([[0.9806, 0.0194]]),\n tensor([[0.9969, 0.0031]]),\n tensor([[0.9968, 0.0032]]),\n tensor([[0.9970, 0.0030]]),\n tensor([[0.9829, 0.0171]]),\n tensor([[0.9952, 0.0048]]),\n tensor([[0.9760, 0.0240]]),\n tensor([[0.9883, 0.0117]]),\n tensor([[0.9916, 0.0084]]),\n tensor([[0.9935, 0.0065]]),\n tensor([[0.9821, 0.0179]]),\n tensor([[0.9782, 0.0218]]),\n tensor([[0.9744, 0.0256]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9977, 0.0023]]),\n tensor([[0.9719, 0.0281]]),\n tensor([[0.9718, 0.0282]]),\n tensor([[0.9871, 0.0129]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9928, 0.0072]]),\n tensor([[0.9655, 0.0345]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9969, 0.0031]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9965, 0.0035]]),\n tensor([[0.9908, 0.0092]]),\n tensor([[0.9709, 0.0291]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9636, 0.0364]]),\n tensor([[0.9925, 0.0075]]),\n tensor([[0.9758, 0.0242]]),\n tensor([[0.9781, 0.0219]]),\n tensor([[0.9970, 0.0030]]),\n tensor([[0.9975, 0.0025]]),\n tensor([[0.9668, 0.0332]]),\n tensor([[0.9637, 0.0363]]),\n tensor([[0.9946, 0.0054]]),\n tensor([[9.9994e-01, 6.4975e-05]]),\n tensor([[0.9962, 0.0038]]),\n tensor([[0.9864, 0.0136]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9965, 0.0035]]),\n tensor([[0.9846, 0.0154]]),\n tensor([[0.9802, 0.0198]]),\n tensor([[0.9897, 0.0103]]),\n tensor([[0.9816, 0.0184]]),\n tensor([[0.9850, 0.0150]]),\n tensor([[0.9664, 0.0336]]),\n tensor([[0.9962, 0.0038]]),\n tensor([[0.9763, 0.0237]]),\n tensor([[0.9783, 0.0217]]),\n tensor([[0.9970, 0.0030]]),\n tensor([[0.9938, 0.0062]]),\n tensor([[0.9940, 0.0060]]),\n tensor([[0.9688, 0.0312]]),\n tensor([[0.9789, 0.0211]]),\n tensor([[0.9885, 0.0115]]),\n tensor([[0.9926, 0.0074]]),\n tensor([[0.9882, 0.0118]]),\n tensor([[0.9785, 0.0215]]),\n tensor([[0.9641, 0.0359]]),\n tensor([[0.9971, 0.0029]]),\n tensor([[0.9922, 0.0078]]),\n tensor([[0.9778, 0.0222]]),\n tensor([[0.9936, 0.0064]]),\n tensor([[0.9882, 0.0118]]),\n tensor([[0.9916, 0.0084]]),\n tensor([[1.0000e+00, 1.2656e-07]]),\n tensor([[0.9749, 0.0251]]),\n tensor([[0.9794, 0.0206]]),\n tensor([[0.9931, 0.0069]]),\n tensor([[0.9977, 0.0023]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9789, 0.0211]]),\n tensor([[0.9900, 0.0100]]),\n tensor([[0.9868, 0.0132]]),\n tensor([[0.9886, 0.0114]]),\n tensor([[0.9810, 0.0190]]),\n tensor([[0.9638, 0.0362]]),\n tensor([[0.9873, 0.0127]]),\n tensor([[0.9942, 0.0058]]),\n tensor([[0.9955, 0.0045]]),\n tensor([[0.9856, 0.0144]]),\n tensor([[0.9901, 0.0099]]),\n tensor([[0.9826, 0.0174]]),\n tensor([[0.9950, 0.0050]]),\n tensor([[1.0000e+00, 1.3504e-11]]),\n tensor([[0.9910, 0.0090]]),\n tensor([[0.9880, 0.0120]]),\n tensor([[0.9806, 0.0194]]),\n tensor([[0.9904, 0.0096]]),\n tensor([[0.9743, 0.0257]]),\n tensor([[0.9830, 0.0170]]),\n tensor([[0.9912, 0.0088]]),\n tensor([[0.9876, 0.0124]]),\n tensor([[0.9901, 0.0099]]),\n tensor([[0.9937, 0.0063]]),\n tensor([[0.9985, 0.0015]]),\n tensor([[0.9721, 0.0279]]),\n tensor([[0.9651, 0.0349]]),\n tensor([[0.9715, 0.0285]]),\n tensor([[0.9939, 0.0061]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9902, 0.0098]]),\n tensor([[0.9696, 0.0304]]),\n tensor([[0.9782, 0.0218]]),\n tensor([[0.9715, 0.0285]]),\n tensor([[0.9906, 0.0094]]),\n tensor([[0.9831, 0.0169]]),\n tensor([[0.9880, 0.0120]]),\n tensor([[0.9957, 0.0043]]),\n tensor([[0.9712, 0.0288]]),\n tensor([[0.9740, 0.0260]]),\n tensor([[0.9723, 0.0277]]),\n tensor([[0.9965, 0.0035]]),\n tensor([[0.9797, 0.0203]]),\n tensor([[0.9890, 0.0110]]),\n tensor([[0.9816, 0.0184]]),\n tensor([[0.9745, 0.0255]]),\n tensor([[0.9775, 0.0225]]),\n tensor([[9.9992e-01, 7.9605e-05]]),\n tensor([[0.9633, 0.0367]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9875, 0.0125]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9915, 0.0085]]),\n tensor([[0.9984, 0.0016]]),\n tensor([[0.9961, 0.0039]]),\n tensor([[0.9801, 0.0199]]),\n tensor([[0.9941, 0.0059]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9895, 0.0105]]),\n tensor([[0.9926, 0.0074]]),\n tensor([[0.9786, 0.0214]]),\n tensor([[0.9874, 0.0126]]),\n tensor([[0.9892, 0.0108]]),\n tensor([[0.9830, 0.0170]]),\n tensor([[0.9887, 0.0113]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9769, 0.0231]]),\n tensor([[0.9853, 0.0147]]),\n tensor([[0.9688, 0.0312]]),\n tensor([[0.9823, 0.0177]]),\n tensor([[0.9782, 0.0218]]),\n tensor([[0.9700, 0.0300]]),\n tensor([[0.9840, 0.0160]]),\n tensor([[0.9824, 0.0176]]),\n tensor([[0.9699, 0.0301]]),\n tensor([[0.9936, 0.0064]]),\n tensor([[0.9912, 0.0088]]),\n tensor([[0.9855, 0.0145]]),\n tensor([[0.9665, 0.0335]]),\n tensor([[0.9989, 0.0011]]),\n tensor([[0.9684, 0.0316]]),\n tensor([[9.9984e-01, 1.5854e-04]]),\n tensor([[0.9631, 0.0369]]),\n tensor([[0.9767, 0.0233]]),\n tensor([[0.9780, 0.0220]]),\n tensor([[0.9886, 0.0114]]),\n tensor([[0.9717, 0.0283]]),\n tensor([[0.9917, 0.0083]]),\n tensor([[0.9768, 0.0232]]),\n tensor([[0.9948, 0.0052]]),\n tensor([[0.9801, 0.0199]]),\n tensor([[0.9985, 0.0015]]),\n tensor([[0.9769, 0.0231]]),\n tensor([[0.9777, 0.0223]]),\n tensor([[0.9761, 0.0239]]),\n tensor([[0.9716, 0.0284]]),\n tensor([[0.9780, 0.0220]]),\n tensor([[0.9815, 0.0185]]),\n tensor([[0.9804, 0.0196]]),\n tensor([[0.9738, 0.0262]]),\n tensor([[0.9884, 0.0116]]),\n tensor([[0.9662, 0.0338]]),\n tensor([[0.9973, 0.0027]]),\n tensor([[0.9759, 0.0241]]),\n tensor([[0.9973, 0.0027]]),\n tensor([[0.9738, 0.0262]]),\n tensor([[0.9789, 0.0211]]),\n tensor([[0.9978, 0.0022]]),\n tensor([[0.9783, 0.0217]]),\n tensor([[0.9794, 0.0206]]),\n tensor([[0.9935, 0.0065]]),\n tensor([[0.9851, 0.0149]]),\n tensor([[0.9837, 0.0163]]),\n tensor([[0.9970, 0.0030]]),\n tensor([[0.9944, 0.0056]]),\n tensor([[0.9969, 0.0031]]),\n tensor([[0.9930, 0.0070]]),\n tensor([[0.9944, 0.0056]]),\n tensor([[0.9908, 0.0092]]),\n tensor([[0.9963, 0.0037]]),\n tensor([[0.9965, 0.0035]]),\n tensor([[0.9683, 0.0317]]),\n tensor([[0.9972, 0.0028]]),\n tensor([[0.9974, 0.0026]]),\n tensor([[0.9957, 0.0043]]),\n tensor([[0.9823, 0.0177]]),\n tensor([[0.9871, 0.0129]]),\n tensor([[0.9947, 0.0053]]),\n tensor([[0.9786, 0.0214]]),\n tensor([[0.9886, 0.0114]]),\n tensor([[0.9972, 0.0028]]),\n tensor([[0.9868, 0.0132]]),\n tensor([[0.9906, 0.0094]]),\n tensor([[0.9951, 0.0049]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9801, 0.0199]]),\n tensor([[0.9911, 0.0089]]),\n tensor([[0.9825, 0.0175]]),\n tensor([[0.9782, 0.0218]]),\n tensor([[0.9696, 0.0304]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9827, 0.0173]]),\n tensor([[0.9764, 0.0236]]),\n tensor([[0.9792, 0.0208]]),\n tensor([[0.9971, 0.0029]]),\n tensor([[0.9760, 0.0240]]),\n tensor([[0.9700, 0.0300]]),\n tensor([[0.9837, 0.0163]]),\n tensor([[0.9902, 0.0098]]),\n tensor([[0.9930, 0.0070]]),\n tensor([[0.9918, 0.0082]]),\n tensor([[0.9777, 0.0223]]),\n tensor([[0.9918, 0.0082]]),\n tensor([[0.9899, 0.0101]]),\n tensor([[0.9737, 0.0263]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9821, 0.0179]]),\n tensor([[0.9796, 0.0204]]),\n tensor([[0.9781, 0.0219]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9870, 0.0130]]),\n tensor([[0.9773, 0.0227]]),\n tensor([[0.9776, 0.0224]]),\n tensor([[0.9814, 0.0186]]),\n tensor([[0.9916, 0.0084]]),\n tensor([[0.9740, 0.0260]]),\n tensor([[0.9826, 0.0174]]),\n tensor([[0.9954, 0.0046]]),\n tensor([[0.9805, 0.0195]]),\n tensor([[0.9735, 0.0265]]),\n tensor([[0.9813, 0.0187]]),\n tensor([[0.9842, 0.0158]]),\n tensor([[0.9805, 0.0195]]),\n tensor([[0.9802, 0.0198]]),\n tensor([[0.9879, 0.0121]]),\n tensor([[0.9661, 0.0338]]),\n tensor([[0.9829, 0.0171]]),\n tensor([[0.9955, 0.0045]]),\n tensor([[0.9890, 0.0110]]),\n tensor([[0.9743, 0.0257]]),\n tensor([[0.9896, 0.0104]]),\n tensor([[0.9962, 0.0038]]),\n tensor([[0.9728, 0.0272]]),\n tensor([[0.9739, 0.0261]]),\n tensor([[0.9737, 0.0263]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[9.9940e-01, 6.0061e-04]]),\n tensor([[0.9961, 0.0039]]),\n tensor([[0.9783, 0.0217]]),\n tensor([[0.9919, 0.0081]]),\n tensor([[0.9758, 0.0242]]),\n tensor([[0.9719, 0.0281]]),\n tensor([[0.9702, 0.0298]]),\n tensor([[0.9951, 0.0049]]),\n tensor([[9.9959e-01, 4.1100e-04]]),\n tensor([[0.9809, 0.0191]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9954, 0.0046]]),\n tensor([[0.9972, 0.0028]]),\n tensor([[0.9878, 0.0122]]),\n tensor([[0.9898, 0.0102]]),\n tensor([[0.9764, 0.0236]]),\n tensor([[0.9971, 0.0029]]),\n tensor([[0.9656, 0.0344]]),\n tensor([[0.9801, 0.0199]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9927, 0.0073]]),\n tensor([[0.9812, 0.0188]]),\n tensor([[0.9689, 0.0311]]),\n tensor([[0.9775, 0.0225]]),\n tensor([[0.9740, 0.0260]]),\n tensor([[0.9936, 0.0064]]),\n tensor([[0.9719, 0.0281]]),\n tensor([[0.9968, 0.0032]]),\n tensor([[0.9666, 0.0334]]),\n tensor([[0.9954, 0.0046]]),\n tensor([[0.9919, 0.0081]]),\n tensor([[0.9988, 0.0012]]),\n tensor([[0.9714, 0.0286]]),\n tensor([[0.9708, 0.0292]]),\n tensor([[0.9944, 0.0056]]),\n tensor([[0.9965, 0.0035]]),\n tensor([[0.9739, 0.0261]]),\n tensor([[0.9782, 0.0218]]),\n tensor([[9.9999e-01, 1.1892e-05]]),\n tensor([[0.9782, 0.0218]]),\n tensor([[0.9842, 0.0158]]),\n tensor([[0.9870, 0.0130]]),\n tensor([[0.9692, 0.0308]]),\n tensor([[0.9658, 0.0342]]),\n tensor([[0.9857, 0.0143]]),\n tensor([[0.9786, 0.0214]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9889, 0.0111]]),\n tensor([[0.9785, 0.0215]]),\n tensor([[0.9963, 0.0037]]),\n tensor([[0.9716, 0.0284]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9791, 0.0209]]),\n tensor([[0.9787, 0.0213]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9929, 0.0071]]),\n tensor([[0.9864, 0.0136]]),\n tensor([[0.9780, 0.0220]]),\n tensor([[0.9739, 0.0261]]),\n tensor([[0.9917, 0.0083]]),\n tensor([[0.9909, 0.0091]]),\n tensor([[0.9864, 0.0136]]),\n tensor([[0.9936, 0.0064]]),\n tensor([[0.9919, 0.0081]]),\n tensor([[9.9986e-01, 1.3707e-04]]),\n tensor([[0.9747, 0.0253]]),\n tensor([[0.9867, 0.0133]]),\n tensor([[9.9914e-01, 8.5790e-04]]),\n tensor([[0.9917, 0.0083]]),\n tensor([[0.9943, 0.0057]]),\n tensor([[0.9940, 0.0060]]),\n tensor([[0.9806, 0.0194]]),\n tensor([[0.9935, 0.0065]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9771, 0.0229]]),\n tensor([[0.9958, 0.0042]]),\n tensor([[0.9874, 0.0126]]),\n tensor([[0.9697, 0.0303]]),\n tensor([[0.9846, 0.0154]]),\n tensor([[0.9871, 0.0129]]),\n tensor([[0.9936, 0.0064]]),\n tensor([[9.9999e-01, 9.4334e-06]]),\n tensor([[0.9953, 0.0047]]),\n tensor([[0.9791, 0.0209]]),\n tensor([[0.9933, 0.0067]]),\n tensor([[0.9750, 0.0250]]),\n tensor([[0.9879, 0.0121]]),\n tensor([[0.9798, 0.0202]]),\n tensor([[0.9850, 0.0150]]),\n tensor([[0.9812, 0.0188]]),\n tensor([[0.9699, 0.0301]]),\n tensor([[0.9783, 0.0217]]),\n tensor([[0.9822, 0.0178]]),\n tensor([[0.9970, 0.0030]]),\n tensor([[0.9930, 0.0070]]),\n tensor([[0.9837, 0.0163]]),\n tensor([[0.9753, 0.0247]]),\n tensor([[0.9883, 0.0117]]),\n tensor([[0.9970, 0.0030]]),\n tensor([[0.9701, 0.0299]]),\n tensor([[0.9969, 0.0031]]),\n tensor([[0.9882, 0.0118]]),\n tensor([[0.9822, 0.0178]]),\n tensor([[0.9777, 0.0223]]),\n tensor([[0.9691, 0.0309]]),\n tensor([[0.9677, 0.0323]]),\n tensor([[0.9787, 0.0213]]),\n tensor([[0.9899, 0.0101]]),\n tensor([[0.9699, 0.0301]]),\n tensor([[0.9833, 0.0167]]),\n tensor([[0.9867, 0.0133]]),\n tensor([[0.9743, 0.0257]]),\n tensor([[0.9827, 0.0173]]),\n tensor([[0.9855, 0.0145]]),\n tensor([[0.9763, 0.0237]]),\n tensor([[0.9669, 0.0331]]),\n tensor([[0.9830, 0.0170]]),\n tensor([[0.9814, 0.0186]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9960, 0.0040]]),\n tensor([[0.9685, 0.0315]]),\n tensor([[0.9820, 0.0180]]),\n tensor([[0.9902, 0.0098]]),\n tensor([[0.9751, 0.0249]]),\n tensor([[0.9807, 0.0193]]),\n tensor([[0.9721, 0.0279]]),\n tensor([[0.9962, 0.0038]]),\n tensor([[0.9853, 0.0147]]),\n tensor([[0.9970, 0.0030]]),\n tensor([[0.9748, 0.0252]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9924, 0.0076]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9930, 0.0070]]),\n tensor([[0.9906, 0.0094]]),\n tensor([[0.9990, 0.0010]]),\n tensor([[0.9932, 0.0068]]),\n tensor([[0.9962, 0.0038]]),\n tensor([[0.9657, 0.0343]]),\n tensor([[0.9772, 0.0228]]),\n tensor([[0.9972, 0.0028]]),\n tensor([[0.9862, 0.0138]]),\n tensor([[0.9887, 0.0113]]),\n tensor([[0.9930, 0.0070]]),\n tensor([[0.9730, 0.0270]]),\n tensor([[0.9956, 0.0044]]),\n tensor([[0.9965, 0.0035]]),\n tensor([[0.9867, 0.0133]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9949, 0.0051]]),\n tensor([[0.9968, 0.0032]]),\n tensor([[0.9974, 0.0026]]),\n tensor([[0.9794, 0.0206]]),\n tensor([[0.9880, 0.0120]]),\n tensor([[0.9870, 0.0130]]),\n tensor([[0.9907, 0.0093]]),\n tensor([[0.9949, 0.0051]]),\n tensor([[0.9818, 0.0182]]),\n tensor([[0.9821, 0.0179]]),\n tensor([[0.9957, 0.0043]]),\n tensor([[0.9877, 0.0123]]),\n tensor([[0.9973, 0.0027]]),\n tensor([[0.9733, 0.0267]]),\n tensor([[0.9960, 0.0040]]),\n tensor([[0.9755, 0.0245]]),\n tensor([[0.9962, 0.0038]]),\n tensor([[9.9900e-01, 9.9593e-04]]),\n tensor([[0.9975, 0.0025]]),\n tensor([[0.9785, 0.0215]]),\n tensor([[0.9963, 0.0037]]),\n tensor([[0.9923, 0.0077]]),\n tensor([[0.9706, 0.0294]]),\n tensor([[0.9962, 0.0038]]),\n tensor([[0.9916, 0.0084]]),\n tensor([[0.9983, 0.0017]]),\n tensor([[0.9956, 0.0044]]),\n tensor([[0.9989, 0.0011]]),\n tensor([[0.9860, 0.0140]]),\n tensor([[0.9847, 0.0153]]),\n tensor([[0.9787, 0.0213]]),\n tensor([[0.9971, 0.0029]]),\n tensor([[0.9913, 0.0087]]),\n tensor([[0.9718, 0.0282]]),\n tensor([[0.9772, 0.0228]]),\n tensor([[0.9965, 0.0035]]),\n tensor([[0.9950, 0.0050]]),\n tensor([[0.9971, 0.0029]]),\n tensor([[0.9803, 0.0197]]),\n tensor([[0.9906, 0.0094]]),\n tensor([[0.9897, 0.0103]]),\n tensor([[9.9999e-01, 7.7291e-06]]),\n tensor([[0.9916, 0.0084]]),\n tensor([[0.9640, 0.0360]]),\n tensor([[0.9852, 0.0148]]),\n tensor([[0.9782, 0.0218]]),\n tensor([[0.9869, 0.0131]]),\n tensor([[0.9934, 0.0066]]),\n tensor([[0.9831, 0.0169]]),\n tensor([[0.9941, 0.0059]]),\n tensor([[0.9818, 0.0182]]),\n tensor([[0.9726, 0.0274]]),\n tensor([[0.9768, 0.0232]]),\n tensor([[0.9932, 0.0068]]),\n tensor([[0.9694, 0.0306]]),\n tensor([[0.9794, 0.0206]]),\n tensor([[0.9962, 0.0038]]),\n tensor([[0.9650, 0.0350]]),\n tensor([[1.0000e+00, 3.9635e-06]]),\n tensor([[9.9932e-01, 6.7779e-04]]),\n tensor([[0.9706, 0.0294]]),\n tensor([[0.9959, 0.0041]]),\n tensor([[0.9813, 0.0187]]),\n tensor([[0.9761, 0.0239]]),\n tensor([[0.9943, 0.0057]]),\n tensor([[0.9730, 0.0270]]),\n tensor([[0.9832, 0.0168]]),\n tensor([[0.9978, 0.0022]]),\n tensor([[0.9819, 0.0181]]),\n tensor([[0.9973, 0.0027]]),\n tensor([[0.9990, 0.0010]]),\n tensor([[0.9820, 0.0180]]),\n tensor([[0.9833, 0.0167]]),\n tensor([[0.9905, 0.0095]]),\n tensor([[0.9962, 0.0038]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9699, 0.0301]]),\n tensor([[0.9717, 0.0283]]),\n tensor([[0.9966, 0.0034]]),\n tensor([[0.9967, 0.0033]]),\n tensor([[0.9683, 0.0317]]),\n tensor([[0.9980, 0.0020]]),\n tensor([[0.9944, 0.0056]]),\n tensor([[0.9951, 0.0049]]),\n tensor([[0.9722, 0.0278]]),\n tensor([[0.9809, 0.0191]]),\n tensor([[0.9972, 0.0028]]),\n tensor([[0.9918, 0.0082]]),\n tensor([[0.9932, 0.0068]]),\n tensor([[0.9925, 0.0075]]),\n tensor([[9.9942e-01, 5.7656e-04]]),\n tensor([[0.9868, 0.0132]]),\n tensor([[0.9963, 0.0037]]),\n tensor([[0.9683, 0.0317]]),\n tensor([[0.9969, 0.0031]]),\n tensor([[0.9698, 0.0302]]),\n tensor([[0.9696, 0.0304]]),\n tensor([[0.9962, 0.0038]]),\n tensor([[0.9922, 0.0078]]),\n tensor([[0.9974, 0.0026]]),\n tensor([[9.9905e-01, 9.5487e-04]]),\n tensor([[0.9792, 0.0208]]),\n tensor([[0.9761, 0.0239]]),\n tensor([[0.9863, 0.0137]]),\n tensor([[0.9633, 0.0367]]),\n tensor([[0.9895, 0.0105]]),\n tensor([[0.9761, 0.0239]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9832, 0.0168]]),\n tensor([[0.9658, 0.0342]]),\n tensor([[0.9816, 0.0184]]),\n tensor([[0.9972, 0.0028]]),\n tensor([[0.9807, 0.0193]]),\n tensor([[0.9975, 0.0025]]),\n tensor([[0.9972, 0.0028]]),\n tensor([[0.9965, 0.0035]]),\n tensor([[0.9723, 0.0277]]),\n tensor([[0.9965, 0.0035]]),\n tensor([[0.9965, 0.0035]]),\n tensor([[0.9942, 0.0058]]),\n tensor([[9.9993e-01, 6.7343e-05]]),\n tensor([[0.9817, 0.0183]]),\n tensor([[0.9985, 0.0015]]),\n tensor([[0.9829, 0.0171]]),\n tensor([[0.9763, 0.0237]]),\n tensor([[0.9736, 0.0264]]),\n tensor([[0.9814, 0.0186]]),\n tensor([[0.9881, 0.0119]]),\n tensor([[9.9980e-01, 2.0152e-04]]),\n tensor([[9.9993e-01, 6.9400e-05]]),\n tensor([[0.9667, 0.0333]]),\n tensor([[0.9922, 0.0078]]),\n tensor([[0.9668, 0.0332]]),\n tensor([[0.9964, 0.0036]]),\n tensor([[0.9723, 0.0277]]),\n tensor([[0.9822, 0.0178]]),\n tensor([[0.9883, 0.0117]]),\n tensor([[0.9879, 0.0121]]),\n tensor([[0.9920, 0.0080]]),\n tensor([[9.9942e-01, 5.8317e-04]]),\n tensor([[0.9795, 0.0205]]),\n tensor([[0.9731, 0.0269]]),\n tensor([[0.9769, 0.0231]]),\n tensor([[0.9877, 0.0123]]),\n tensor([[0.9836, 0.0164]]),\n tensor([[0.9903, 0.0097]]),\n tensor([[0.9990, 0.0010]]),\n tensor([[0.9969, 0.0031]]),\n tensor([[0.9976, 0.0024]]),\n tensor([[0.9765, 0.0235]]),\n tensor([[9.9994e-01, 6.3071e-05]]),\n tensor([[0.9910, 0.0090]]),\n tensor([[0.9965, 0.0035]]),\n tensor([[0.9763, 0.0237]]),\n ...]"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 2, 5, 4],\n        [1, 2, 3, 4],\n        [2, 2, 3, 4]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.cat(a,dim=0)\n",
    "c"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "finall_result = torch.cat(results, dim = 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.9969, 0.0031],\n        [0.9739, 0.0261],\n        [0.9914, 0.0086],\n        ...,\n        [0.9807, 0.0193],\n        [0.9806, 0.0194],\n        [0.9977, 0.0023]])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finall_result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.9969, 0.0031])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finall_result[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "torch.save(finall_result, save_dir+'/results.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "a19db2dd",
   "metadata": {},
   "source": [
    "## 3. 作业评分\n",
    "\n",
    "**作业要求**：    \n",
    "                         \n",
    "1. 请加载你认为训练最佳的模型（不限于图神经网络)\n",
    "2. 提交的作业包括【程序报告.pdf】和代码文件。\n",
    "\n",
    "**注意：**\n",
    "          \n",
    "1. 在训练模型等过程中如果需要**保存数据、模型**等请写到 **results** 文件夹，如果采用 [离线任务](https://momodel.cn/docs/#/zh-cn/%E5%9C%A8GPU%E6%88%96CPU%E8%B5%84%E6%BA%90%E4%B8%8A%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B) 请务必将模型保存在 **results** 文件夹下。\n",
    "2. 训练出自己最好的模型后，先按照下列 cell 操作方式实现 NoteBook 加载模型测试；请测试通过在进行【系统测试】。\n",
    "3. 点击左侧栏`提交作业`后点击`生成文件`则只需勾选 `predict()` 函数的cell，即【**模型预测代码答题区域**】的 cell。\n",
    "4. 请导入必要的包和第三方库 (包括此文件中曾经导入过的)。\n",
    "5. 请加载你认为训练最佳的模型，即请按要求填写**模型路径**。\n",
    "6. `predict()`函数的输入和输出请不要改动。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea1caeb",
   "metadata": {},
   "source": [
    "===========================================  **模型预测代码答题区域**  =========================================== \n",
    "\n",
    "在下方的代码块中编写 **模型预测** 部分的代码，请勿在别的位置作答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcaa638d",
   "metadata": {
    "select": true
   },
   "outputs": [],
   "source": [
    "## 生成 main.py 时请勾选此 cell\n",
    "from utils import DGraphFin\n",
    "from utils.evaluator import Evaluator\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def predict(data,node_id):\n",
    "    \"\"\"\n",
    "    加载模型和模型预测\n",
    "    :param node_id: int, 需要进行预测节点的下标\n",
    "    :return: tensor, 类0以及类1的概率, torch.size[1,2]\n",
    "    \"\"\"\n",
    "    # 这里可以加载你的模型\n",
    "    model = \n",
    "    model.load_state_dict(torch.load('./results/model.pt'))\n",
    "    # 模型预测时，测试数据已经进行了归一化处理\n",
    "    # -------------------------- 实现模型预测部分的代码 ---------------------------\n",
    "\n",
    "    \n",
    "    return y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
