#  Assignment 3: Naive Bayes/Logistic Regression Classification

在本作业中，您将应用机器学习技术进行图像和文本分类任务，并应用逻辑回归分类器进行二元分类。

## Programming language

你只能使用 Python 标准库和 numpy 中的模块。

## Contents 

• Part 1: Image Classification 
• Part 2: Text Classification 
• Part 3: Linear Classifier 
• Extra Credit 
• Provided Code Skeleton 
• Deliverables 
• Report checklist 

# Part 1: Image Classification 

![Image from Baidu](https://s2.loli.net/2022/11/07/aeUdY1To8rjQtqI.png)

**Data：**为您提供了 Digit Mnist 数据集的一部分。有 55000 个训练样例和 10000 个测试样例。标签从 0 到 9，分别代表 0、1、2、3、4、5、6、7、8 和 9 的数字。在本节中，您将应用朴素贝叶斯模型来完成此任务。

## Naive Bayes model-朴素贝叶斯模型 

- **特征：**每张图像由 28\*28 像素组成，我们将其表示为大小为 784 的扁平阵列，其中每个特征/像素 Fi 的强度值从 0 到 255（8 位灰度）。

- **训练：**训练阶段的目标是估计每个像素位置 i 和每个数字类别（0、1、2、3、4、5、6、7、8、9）的**可能性 (likelihood)** `P(Fi | class) ）`。似然估计定义为 

  `P(Fi = f | class) = (# of times pixel i has value f in this class of training examples) / (Total # of training examples from this class) `

  您必须**平滑(smooth)**可能性以确保没有零计数。拉普拉斯平滑是一种非常简单的方法，它将每个值 f 的观察计数增加某个常数 k。这对应于将 k 添加到上面的分子，并将 k*V 添加到分母（其中 V 是特征可以采用的可能值的数量）。 k值越高，平滑越强。尝试使用不同的 k 值（例如，从 0.1 到 10）并找到能够提供最高分类准确度的值。

  您还应该通过训练集中不同类别的经验频率来估计**先验(priors)**  `P(class)`。

- **测试：**您将根据学习的朴素贝叶斯模型对测试数字类进行最大后验（MAP）分类。假设测试图像具有特征值 f1, f2, ... , f784。根据这个模型，给定数字的每个类别的后验概率（按比例）由

   `P(class) ⋅ P(f1 | class) ⋅ P(f2 | class) ⋅ ... ⋅ P(f784 | class ) `

  请注意，为了避免下溢，使用上述数量的日志是标准的：

  `log P(class) + log P(f1 | class) + log P(f2 | class) + ... + log P (f784 | class) `

  在为每个测试图像计算所有十个类别的上述决策函数值后，您将使用它们进行 MAP 分类。

-  **评估：**根据**平均分类率(average classification rate)**和**每个数字的分类率(classification 
  rate for each digit )**（给定项目的所有测试图像正确分类的百分比）报告您的表现。还要报告您的**混淆矩阵(confusion matrix)**。这是一个 10x10 矩阵，其 r 行和 c 列中的条目是来自 r 类的测试图像被归类为 c 类的百分比。此外，对于每个类，根据您的分类器显示该类中具有最高和最低后验概率的测试示例。您可以将这些视为每个数字类中最多和最不“典型”的实例（而最不“典型”的实例可能被错误分类）。

- 似然可视化：

  在实际领域中使用分类器时，能够检查他们所学的内容非常重要。检查朴素贝叶斯模型的一种方法是查看给定标签的最可能特征。理解参数的另一个工具是可视化每个类别的高强度像素的特征可能性。这里的高强度是指从 128 到 255 的像素值。

  因此，类 c~1~的高强度像素特征 Fi 的可能性是类 c~1~ 像素位置 i 的前 128 个强度的概率之和。

  $$
  Feature \quad likelihood(F_i,c_1)=\sum_{k=128}^{255}P(F_i=k \mid c_1)
  $$
  

  对于十个类别中的每一个，绘制他们训练的高强度像素特征的可能性，看看他们学到了什么可能性。

# Part 2: Text Classification 

您将获得一个由属于 14 个不同类别的文本组成的数据集。我们将数据集拆分为训练集和开发数据集。训练集包含 3865 个文本及其对应的 1-14 类标签，每个类都有实例，开发集包含 483 个测试实例及其对应的标签。我们已经完成了数据集的预处理并提取到 text_main.py 中的 Python 列表结构中。使用训练集，您将学习一个朴素贝叶斯分类器，该分类器将在给定看不见的文本的情况下预测正确的类标签。使用开发集来测试学习模型的准确性。报告您在开发集上获得的准确性、召回率和 F1 分数。我们将有一个单独的（看不见的）训练/测试集，我们将在您提交代码后使用它来运行您的代码。不能使用其他外部非标准 python 库。

## 一元模型

NLP 中的词袋模型是一个简单的一元模型，它将文本表示为一个独立词袋。也就是说，我们忽略了单词出现的位置，只关注它们在文本中出现的频率。这里每个文本都由一组单词组成。使用贝叶斯定理，您需要计算文本属于给定文本中单词的 14 个类别之一的概率。因此，您需要估计后验概率：
$$
P(Class=C_i \mid Words)=\frac{P(Class=C_i)}{P(Words)} \prod_{All \quad words}P(Word \mid Class=C_i)
$$
标准做法是使用对数概率以避免下溢。此外，`P(words) `只是一个常数，因此不会影响您的计算

## 训练和发展

- **训练：**要训练算法，您需要使用文本构建词袋模型。建立模型后，您需要估计对数似然 $log{P(WordType=C_i)} $ 变量`Ci`只能取 14 个值，1-14。此外，您需要确保平滑可能性以防止零概率。为了完成这个任务，使用拉普拉斯

- **开发：**计算对数似然后，您将让您的模型从开发集中预测文本的类别标签。为此，您将使用上面显示的等式进行 MAP 估计分类。

  仅使用训练集来学习个体概率。以下结果应放入您的报告中：

  1. 绘制您的混淆矩阵。这是一个 14x14 矩阵，其 r 行和 c 列中的条目是类别 r 中分类为类别 c 的测试文本的百分比。
  2. 开发集上每个类的准确率、召回率和 F1 分数。
  3. 每个类别的前 20 个特征词。
  4. 计算您的准确度，而不包括先验类到朴素贝叶斯方程中，即只计算每个实例的 ML 推理。报告准确度数字的变化，如果有的话。还要说明你对此观察的理由。包括先验课程总是有益的吗？在均匀分布之前更改您的班级。结果有何变化？

# Part 3: Linear Classifier 

![Image by TA](https://s2.loli.net/2022/11/07/qeuwcPOaTmyhkpn.png)

二维平面上有一些点，其中一些标记为 1，另一些标记为 0。你的任务是找到能够正确分隔这两类点的边界线。如上图，实线为真实边界，虚线为逻辑回归分类器找到的边界。

**注意：**

a）您需要为此任务实现逻辑回归分类器。该logistic.py 是您需要在本节中修改的唯一文件。

b) 虽然我们在这个任务中只对二维点进行分类，但您的代码应该在任意维度上工作。

## 逻辑回归模型

逻辑回归模型，又称可微感知器，如下：
$$
f(\vec{w}^T \vec{f})=sigmoid(\vec{w}^T \vec{f})= \frac{1}{1+e^{-\vec{w}^T \vec{f}}}
$$


**注意：**

a) 这个逻辑回归模型与讲座幻灯片中的模型不同。你应该在这个任务中实现这个，而**不是**幻灯片中的那个。

b) sigmoid 函数的导数是 $f'(x)=f(x) \times (1-f(x))$

- **特征：**每个点的坐标。点数为N，坐标维数为P，特征矩阵为P*N。

- **训练：**实现逻辑回归模型的训练过程。回想一下讲座幻灯片中逻辑回归的损失函数，如下所示：（注意：更好的测量是逻辑损失，这在本 MP 中不需要。如果您有兴趣，请参阅此处的逻辑回归[Logistic regression](https://en.wikipedia.org/wiki/Logistic_regression#%3A~%3Atext%3DLogistic regression is a statistical%2Ca form of binary regression))。）
  $$
  L(y_1,\ldots,y_n,\vec{f_1},\ldots,\vec{f_n})=\sum_{i=1}^{n}(y_i-sigmoid(\vec{w}^T \vec{f}))^2
  $$
  

- **测试：**提供的代码已经为你实现了测试过程。你**不需要**实现这一点。但**不要忘记**在您的报告中报告测试结果。

- **评估：**我们多次重复训练和测试的过程，以平均训练误差和测试误差作为我们对模型的评估。这也是为您在骨架代码中实现的。

# Extra Credit 

在二元模型上实现朴素贝叶斯算法，而不是一元模型。 Bigram 模型定义如下： 
$$
P(w_1,\ldots,w_n)=P(w_i)P(W_2 \mid w_1)\ldots P(w_n\mid w_{n-1})
$$
然后将 bigram 模型和 unigram 模型组合成一个以参数 λ 定义的混合模型：
$$
(1-\lambda)P(Y)\prod_{i=1}^{n}P(w_i \mid Y)+\lambda P(Y)\prod_{i=1}^{m}P(b_i\mid Y)
$$
二元模型是否有助于提高准确性？找到给出最高分类精度的最佳参数 λ。报告最佳参数 λ 并报告您在二元模型和最佳混合模型上的结果（准确度数），并回答以下问题： 

1. 在二元模型上运行朴素贝叶斯会稍微放松模型的朴素假设。然而，这总是一件好事吗？为什么或者为什么不？ 
2. 如果我们做一个 N 是一个非常大的数字的 N-gram 模型会发生什么？

# Provided Code Skeleton 

我们提供了（zip 文件）所有代码，让您开始使用 MP。

对于第 1 部分，您将获得以下内容。 python 文件中的文档字符串解释了每个函数的用途。

- image_main.py- 这是加载数据集并调用朴素贝叶斯算法的主文件。
- naive_bayes.py- 这是唯一需要修改的文件。

- x_train.npy、y_train.npy、x_test.npy 和 y_test.npy - 这些文件包含训练和测试示例。


  对于第 2 部分，您将获得以下内容。 python 文件中的文档字符串解释了每个函数的用途

- text_main.py- 这是加载数据集并调用您的朴素贝叶斯算法的主文件。

- TextClassifier.py- 这是唯一需要修改的文件。

- train_text.csv- 此文件包含训练示例。

- dev_text.csv- 此文件包含用于测试模型的开发示例。

- stop_words.csv - 此文件包含预处理数据集所需的停用词。


对于第 3 部分，您将获得以下内容。 python 文件中的文档字符串解释了每个函数的用

- linear_classifier_main.py- 这是加载数据集并调用感知器和逻辑回归算法的主文件。

- logistic.py-这是唯一需要修改以实现逻辑回归算法的文件。

- mkdata.py - 这是为您的算法生成合成数据的文件。

- plotdata.py - 此文件用于绘制感知器模型的实验结果。

- plotdata_log_reg.py- 该文件用于绘制您的逻辑回归模型的实验结果。

# Deliverables 

该 MP 将通过blackboard提交。

  请**仅将以下文件上传到黑板**:

    1. naive_bayes.py - 第 1 部分的解决方案 Python 文件 
    2. TextClassifier.py - 第 2 部分的解决方案 Python 文件 
    3. logistic.py - 第 3 部分的解决方案 Python 文件 
    4. report.pdf - pdf 格式的项目报告格式

# Report checklist 

您的报告应简要描述您实施的解决方案，并全面回答作业每个部分的问题。您的描述应侧重于解决方案中最“有趣”的方面，即任何不明显的实现选择和参数设置，以及您发现对获得良好性能特别重要的内容。如果需要它们来阐明您的方法，请随意包含伪代码或图形。您的报告应该是独立的，并且应该（理想情况下）使我们能够理解您的解决方案，而无需运行您的源代码。

请按照以下方式组织报告： 

1. 标题页：所有团队成员的列表，每个成员注册的课程编号和部门，撰写报告的日期 
2. 第 I 部分：图像分类。报告平均分类率、每个类的分类率和混淆矩阵。对于每个类，根据您的分类器显示该类中具有最高和最低后验概率的测试示例。显示十个可视化图，这两个特征的可能性。
3. 第二节：文本分类。报告所有 14 个类别的所有结果、混淆矩阵、召回率、精度、F1 分数。包括每个类的热门特征词。此外，报告当类先验更改为均匀分布以及将其删除时准确性结果的变化。为这些观察提供推理 
4. 第三部分：线性分类器。报告您的逻辑回归模型的所有训练和测试集的平均错误率。显示模型的视觉结果。
5. 额外得分：如果您完成了任何您认为应该获得额外得分的工作，请在此处描述。 
6. 贡献声明：指定哪个团队成员执行了哪个任务。如果适用，我们鼓励您将其设为多对多映射。例如，您可以说“Rahul 和 Jason 都实现了 BFS 功能，他们的结果进行了调试比较，并提交了 Rahul 的代码。Jason 和 Mark 都实现了 DFS 功能，Mark 的代码从未成功运行，因此提交了 Jason 的代码。

报告的第一部分由所有 3 名团队成员撰写。马克和杰森的第二部分，拉胡尔和杰森的第三部分。”……等等。

仅在blackboard上附加作为所需可交付成果的文件。您的报告必须是格式化的 pdf 文件。图片和示例输出应包含在文档中。例外：非常大或不适合包含在 pdf 文档中的项目（例如视频或动画 gif）可能会放在网络上，并且 URL 会包含在您的报告中。**你可以用英文或中文写你的报告。**

## 额外积分

我们保留为您实施的任何高级探索或特别具有挑战性或创造性的解决方案提供**奖励积分**的权利。这包括但不限于上面给出的额外信用建议。