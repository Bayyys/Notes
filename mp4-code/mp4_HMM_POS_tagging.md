# Assignment 4: HMM POS tagging

对于这个MP，你将使用一个HMM模型来实现语音部分（POS）的标记。在你开始写代码之前，请确保你了解这个算法，例如看看隐马尔可夫模型的讲座和Jurafsky和Martin的[第8章](https://web.stanford.edu/~jurafsky/slp3/8.pdf)。

# 一般准则

基本指示与以前的MPs相同。

- 可以获得额外学分，上限为10%。

- 你可以使用numpy（尽管它不是必需的）。你不可以使用其他非标准模块（包括nltk）。

# 问题描述

mp4代码从两个文件中读取数据。你的标签函数将被赋予带标签的训练数据和不带标签的测试数据。你的标签程序应该使用训练数据来估计它所需要的概率，然后使用这个模型来推断测试输入的标签。主mp4函数将把这些与正确的标签进行比较，并报告你的准确性。
数据被划分为句子。你的标签器应该独立处理每个句子。
你将需要编写两个标签函数：

- 基准
- Viterbi：HMM标签器

# 材料

MP的代码包包含三个文件。

- mp4.py（不要改变）
- utils.py（不要改变） 
- baseline.py 
- viterbi_1.py 
- test_viterbi/ 
  - test_viterbi.py 
  - utils.py（不要改变） 
- viterbi_2.py 
- viterbi_ec.py

代码包还包含训练和开发数据 

- Brown语料库： data/brown-training.txt, data/brown-dev.txt 

所提供的代码将所有单词转换为小写。在加载句子时，它还为每个句子添加了一个START和END标签。这些标签只是为了标准化。它们不会在准确性计算中被考虑。

你应该使用训练数据来训练你的模型的参数，并使用开发集来测试其准确性。在你提交后，我们将使用单独的（未见过的）数据集来测试你的代码。

此外，你的代码将在一个你无法获得的隐藏数据集上进行测试，这个数据集的标签和词的数量与提供给你的不同。**因此，不要硬编码你的任何重要计算，如初始概率、过渡概率、排放概率、标签的数量或名称等。我们将检查代码中的硬编码计算/值，并对这种实现方式进行处罚。**
要在布朗语料库数据上运行代码，你需要告诉它数据在哪里，以及运行哪种算法，可以是baseline、viterbi_1、viterbi_2或viterbi_ec： 

`python3 mp4.py --train data/brown-training.txt --test data/brown-dev.txt --algorithm [baseline, viterbi_1, viterbi_2, viterbi_ec] `

程序将运行该算法并报告三个准确数字。

- 总体准确率 
- 对已经看到的有多个不同标签的词的准确率 
- 对未看到的词的准确率

我们的数据集中的许多词只有一个可能的标签，所以很难把标签弄错！这意味着即使是非常简单的算法，也有可能出现错误。 这意味着即使是非常简单的算法也有很高的总体准确率。另外两个准确率数字将帮助你看到哪里有改进的余地。

# 标签集

以下是一个由16个语篇标签组成的示例集。这是在所提供的布朗语料库中使用的标签集。**但请记住，你不应该对这个标签集进行任何硬编码，因为我们将在另外两个具有不同标签集的数据集上测试你的代码。**

- ADJ adjective

- ADV adverb
- IN preposition
- PART particle (e.g. after verb, looks like a preposition)
- PRON pronoun
- NUM number
- CONJ conjunction
- UH filler, exclamation
- TO infinitive
- VERB verb
- MODAL modal verb 
- DET determiner
- NOUN noun
- PERIOD end of sentence punctuation
- PUNCT other punctuation
- X miscellaneous hard-to-classify items

# Part I Baseline tagger

基准标记器独立考虑每个词，忽略之前的词和标记。对于每个词w，它计算w在训练数据中与每个标签一起出现的次数。在处理测试数据时，它始终给w提供最常出现的标签。对于未见过的词，它应该猜测在训练数据集中最常出现的标签。
一个正确工作的基线标记器在布朗语料库开发集上应该得到大约93%的准确率，对多标签词的准确率超过90%，对未见过的词超过69%。

<font color=red>**不要试图改进基线算法。完全按照上面的描述来实现它。**</font>

# Part II Viterbi_1

**如果你觉得这部分开始时很困难**：你可能会发现进入下一节并首先只实现Viterbi算法会更容易。
Viterbi 标记器应该实现在讲座中或Jurafsky和Martin中看到的HMM花架（维特比）解码algoirthm。也就是说，每个标签的概率只取决于前一个标签，而每个词的概率只取决于相应的标签。这个模型将需要估计三组概率。

- 初始概率（每个标签在句子开始时出现的频率是多少？)
- 过渡概率（标签𝑡𝑏跟随标签𝑡𝑎的频率如何？）
- 排放概率（标签t产生词w的频率是多少？）

因此，无论你选择手工编码还是从数据中学习，你的初始概率都会有一个非常有限的形式。教科书/教科书例子中显示的初始概率将由从START标记到第一个实词的过渡概率处理。

将你的处理过程分为五个步骤是很有帮助的。

- 计算标签、标签对、标签/词对的出现次数。

- 计算平滑的概率
- 取每个概率的对数
- 构建网格。注意，对于每个标记/时间对，您不仅必须存储最佳路径的概率，还必须存储指向该路径中前一个标记时间对的指针。
- 返回通过花架的最佳路径。

你需要使用平滑法来获得良好的性能。确保你计算过渡和发射概率的代码永远不会返回0。拉普拉斯平滑法是我们用来平滑计算初始概率、过渡概率和排放概率的零概率情况的方法。

例如，要平滑发射概率，请单独考虑每个标签。对于固定标签 T，您需要确保 𝑃𝑒(𝑊|𝑇) 产生一个非零数字，无论您给它什么词  W 。您可以使用拉普拉斯平滑（如在 MP 3 中）来填充“UNKNOWN”的概率，这将是训练数据中未出现的所有单词 W 的返回值。对于 Viterbi 的初始实现，对所有标记使用相同的拉普拉斯平滑常数 α。

这个简单版本的 Viterbi 将比 Brown 开发数据集的基线代码执行得更差。但是你应该注意到它在多标签词上做得更好（例如超过 93%）。您应该在 viterbi_1.py 中的 viterbi_1 函数下编写这个简单版本的维特比。

# 启动或调试第 2 部分 Viterbi

**这部分是可选的，不应提交。** 但是，如果您发现很难直接尝试第 2 部分，您可能会发现从这里开始更容易。您可以首先使用提供的虚拟示例单独实施或调试您的 Viterbi 实施。 Jurafsky 和 Martin（第 8.4.6 节）提供了一个很好的示例来可视化维特比算法的性能。我们将该示例作为示例测试用例提供给您，以确保您的整个 Viterbi 算法（网格计算和回溯）正常工作。

**test_viterbi.py:** 在这里编写您的 Viterbi 实现，并使用以下命令运行它：

`python3 test_viterbi.py`

一旦你开始工作（如果你从这里开始第 2 部分），你就可以将它扩展到 Brown 数据集，你需要在其中额外计算初始标签概率、看不见的标签和平滑的正确实现。

# Part III Viterbi_2

之前的 Vitebi 标注器未能超过基线，因为它在未见过的词上表现很差。假设所有标签对这些词都有相似的概率，但我们知道一个新词更可能有标签 NOUN 而不是（比如）CONJ。对于这一部分，您将改进发射平滑以匹配未见过单词的真实概率。
在训练数据中出现零次的词（词汇外或 OOV 词）和在训练数据中出现一次的词（[hapax](https://en.wikipedia.org/wiki/Hapax_legomenon)词）往往具有相似的词性 (POS)。因此，与其假设 OOV 词在所有 POS 中均匀分布，不如通过测量 hapax 词的分布来更好地估计它们的分布。从训练数据中提取这些词并计算每个标签在它们上的概率。当您对标签 T 的发射概率进行拉普拉斯平滑时，将拉普拉斯平滑常数缩放 P(T|hapax)，即标签 T 在给定单词为 hapax 的情况下出现的概率。请记住，拉普拉斯平滑的作用是降低高频词的概率质量，并将部分概率质量重新分配给低频词。一个大的平滑常数最终会使概率质量倾斜很多，所以用这个超参数的小数量级进行试验。
这个优化版本的 Viterbi 代码在 Brown 开发数据集上应该有明显更好的不可见词准确率（例如，超过 66.5%）。它还在整体精度上超过了基线（例如 95.5%）。您应该在 viterbi_2.py 中的 viterbi_2 函数下编写优化版本的 Viterbi。
hapax 词标签概率可能因数据集而异。因此，您的 viterbi_2 方法应该在每次运行时根据其训练数据动态计算它们。

## 提示

- 标签“X”很少出现在数据集中。为拉普拉斯平滑常数设置一个高值可能会过度平滑发射概率并破坏您的统计计算。拉普拉斯平滑常数的小值，例如1e-5，可能有帮助。
- 不建议在您的实施中使用全局变量，因为gradescope 在同一个python 环境中运行许多不同的测试。在一次测试期间设置的全局值将延续到后续测试。

# 额外加分：Viterbi_ec

额外信用的任务是最大限度地提高维特比代码的准确性。您必须仅在提供的训练集上进行训练（无外部资源），并且您应该保留算法。但是，您可以根据需要进行任何算法改进。这个优化后的算法应该命名为viterbi_ec。
我们建议尝试提高算法为未见过的词猜测正确标签的能力。如果您检查训练数据中的 hapax 词集，您应该注意到具有某些前缀和某些后缀的词通常具有某些有限类型的标签。例如，后缀为“-ly”的词有几个可能的标签，但标签分布与完整的 hapax 词集有很大不同。您可以通过更改为它们生成的排放概率来更好地处理这些词。
回想一下我们在第 2 部分和第 3 部分中所做的事情：我们将 hapax 词（在训练数据中）和不可见词（在开发或测试数据中）映射到单个伪词“UNKNOWN”。为了利用单词的形式，您可以将 hapax/unseen 单词映射到几个不同的伪单词中。例如。也许所有以“-ing”结尾的词都可以映射到“X-ING”。然后您可以使用 hapax 词为 X-ING 计算合适的概率值，如第 3 部分中所述。
从第一性原理预测有用的前缀和后缀是极其困难的。我们强烈建议您自己构建一个单独的 python 工具，以将 hapax 单词及其标签转储到一个单独的文件中，您可以检查该文件。您可能会假设我们完全隐藏的数据集是英文的，因此来自 Brown 语料库的单词模式应该继续对隐藏语料库有用。
使用这种方法，我们的模型解决方案在未见过的单词上获得了大约 75% 的准确率，总体准确率约为 96%。（这两个数字都在 Brown 开发数据集上.）也可以通过使用两个先前的标签（而不是一个）来预测每个标签来提高性能。但是，您可以通过使用从两个标签中的第一个标签中选择的信息来获得准确性。此外，波束搜索有助于加快解码时间。
评分标准如下：任何总体准确率高于或等于 95.5% 的提交都被视为有效提交。

# Submission

常规 MP 包括提交文件 **baseline.py**、**viterbi_1.py** 和 .EC需要提交文件**viterbi_ec.py**。如果满足额外的信用评分标准，您可以自由地将相同的代码从 viterbi.py 复制到 extra.py。
您的**report.pdf** 应该包括三种类型的基线精度、Viterbi_1 和 Viterbi_2。如果你为了加分做了什么，请解释你做了什么以及它如何帮助提高你的表现。此外，说明每个成员所做的贡献。

